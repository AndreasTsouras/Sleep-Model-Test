{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103fbf1-1ef3-495d-a0b0-831231efd345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert .txt file to csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def map_sleep_stage(stage_str):\n",
    "    stage_str = str(stage_str).lower()\n",
    "    if \"wake\" in stage_str:\n",
    "        return 0\n",
    "    elif \"n1\" in stage_str or \"n2\" in stage_str:\n",
    "        return 1\n",
    "    elif \"n3\" in stage_str or \"sws\" in stage_str:\n",
    "        return 2\n",
    "    elif \"rem\" in stage_str:\n",
    "        return 3\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def clean_and_fill_hr_column(df):\n",
    "    df[\"hr_clean\"] = pd.to_numeric(df[\"hr\"], errors='coerce')\n",
    "    df[\"hr_clean\"] = df[\"hr_clean\"].ffill().bfill()\n",
    "    return df\n",
    "\n",
    "def clean_hr_and_stage(input_csv_path, output_csv_path):\n",
    "    # Load raw data\n",
    "    df = pd.read_csv(input_csv_path, sep=\";\", names=[\"timestamp\", \"hr\", \"stage\"])\n",
    "    \n",
    "    # Clean and fill hr\n",
    "    df = clean_and_fill_hr_column(df)\n",
    "\n",
    "    # Map sleep stage strings to numbers\n",
    "    df[\"sleepstage\"] = df[\"stage\"].apply(map_sleep_stage)\n",
    "\n",
    "    # Drop rows where sleep stage mapping failed (nan)\n",
    "    df = df.dropna(subset=[\"sleepstage\"])\n",
    "\n",
    "    # Keep only needed columns and rename hr_clean to hr\n",
    "    df_cleaned = df[[\"hr_clean\", \"sleepstage\"]].rename(columns={\"hr_clean\": \"hr\"})\n",
    "\n",
    "    # Save cleaned data to CSV\n",
    "    df_cleaned.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Cleaned data saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00a49e-b475-4d42-8617-648908e111ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean all participants\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def process_all_participants(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    files = glob.glob(os.path.join(input_folder, \"*.txt\"))\n",
    "\n",
    "    if not files:\n",
    "        print(\"⚠️ No .txt files found in input folder.\")\n",
    "        return\n",
    "\n",
    "    for file_path in files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        participant_id = os.path.splitext(filename)[0]\n",
    "        output_path = os.path.join(output_folder, f\"{participant_id}_cleaned.csv\")\n",
    "\n",
    "        try:\n",
    "            clean_hr_and_stage(file_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to process {filename}: {e}\")\n",
    "\n",
    "\n",
    "process_all_participants(\"HRV_Model/Heartrate Data\", \"HR_CSV\") #edit input/output directory"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
